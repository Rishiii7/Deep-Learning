{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "name": "pandas.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfxcGxGv2MTp"
      },
      "source": [
        "The following additional libraries are needed to run this\n",
        "notebook. Note that running on Colab is experimental, please report a Github\n",
        "issue if you have any problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kda68qy22MTr",
        "outputId": "9789305d-ec48-47e9-d434-c54853ee56e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install -U mxnet-cu101==1.7.0\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mxnet-cu101==1.7.0\n",
            "  Downloading mxnet_cu101-1.7.0-py2.py3-none-manylinux2014_x86_64.whl (846.0 MB)\n",
            "\u001b[K     |███████████████████████████████▌| 834.1 MB 1.3 MB/s eta 0:00:10tcmalloc: large alloc 1147494400 bytes == 0x55d875bfc000 @  0x7f61a8ced615 0x55d83bf2b02c 0x55d83c00b17a 0x55d83bf2de4d 0x55d83c01fc0d 0x55d83bfa20d8 0x55d83bf9cc35 0x55d83bf2f73a 0x55d83bfa1f40 0x55d83bf9cc35 0x55d83bf2f73a 0x55d83bf9e93b 0x55d83c020a56 0x55d83bf9dfb3 0x55d83c020a56 0x55d83bf9dfb3 0x55d83c020a56 0x55d83bf9dfb3 0x55d83bf2fb99 0x55d83bf72e79 0x55d83bf2e7b2 0x55d83bfa1e65 0x55d83bf9cc35 0x55d83bf2f73a 0x55d83bf9e93b 0x55d83bf9cc35 0x55d83bf2f73a 0x55d83bf9db0e 0x55d83bf2f65a 0x55d83bf9dd67 0x55d83bf9cc35\n",
            "\u001b[K     |████████████████████████████████| 846.0 MB 22 kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu101==1.7.0) (2.23.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu101==1.7.0) (1.19.5)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101==1.7.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101==1.7.0) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101==1.7.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101==1.7.0) (1.24.3)\n",
            "Installing collected packages: graphviz, mxnet-cu101\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-cu101-1.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 0,
        "id": "ohKzVJAQ2MTs"
      },
      "source": [
        "# Data Preprocessing\n",
        ":label:`sec_pandas`\n",
        "\n",
        "So far we have introduced a variety of techniques for manipulating data that are already stored in tensors.\n",
        "To apply deep learning to solving real-world problems,\n",
        "we often begin with preprocessing raw data, rather than those nicely prepared data in the tensor format.\n",
        "Among popular data analytic tools in Python, the `pandas` package is commonly used.\n",
        "Like many other extension packages in the vast ecosystem of Python,\n",
        "`pandas` can work together with tensors.\n",
        "So, we will briefly walk through steps for preprocessing raw data with `pandas`\n",
        "and converting them into the tensor format.\n",
        "We will cover more data preprocessing techniques in later chapters.\n",
        "\n",
        "## Reading the Dataset\n",
        "\n",
        "As an example,\n",
        "we begin by (**creating an artificial dataset that is stored in a\n",
        "csv (comma-separated values) file**)\n",
        "`../data/house_tiny.csv`. Data stored in other\n",
        "formats may be processed in similar ways.\n",
        "\n",
        "Below we write the dataset row by row into a csv file.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 1,
        "tab": [
          "mxnet"
        ],
        "id": "Jq83GdP82MTs"
      },
      "source": [
        "import os\n",
        "\n",
        "os.makedirs(os.path.join('..', 'data'), exist_ok=True)\n",
        "data_file = os.path.join('..', 'data', 'house_tiny.csv')\n",
        "with open(data_file, 'w') as f:\n",
        "    f.write('NumRooms,Alley,Price\\n')  # Column names\n",
        "    f.write('NA,Pave,127500\\n')  # Each row represents a data example\n",
        "    f.write('2,NA,106000\\n')\n",
        "    f.write('4,NA,178100\\n')\n",
        "    f.write('NA,NA,140000\\n')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 2,
        "id": "OeKLLKdG2MTt"
      },
      "source": [
        "To [**load the raw dataset from the created csv file**],\n",
        "we import the `pandas` package and invoke the `read_csv` function.\n",
        "This dataset has four rows and three columns, where each row describes the number of rooms (\"NumRooms\"), the alley type (\"Alley\"), and the price (\"Price\") of a house.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 3,
        "tab": [
          "mxnet"
        ],
        "id": "y9SUe-w02MTt",
        "outputId": "1491c118-a809-4750-ee1e-727d7b06defb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# If pandas is not installed, just uncomment the following line:\n",
        "# !pip install pandas\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(data_file)\n",
        "print(data)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   NumRooms Alley   Price\n",
            "0       NaN  Pave  127500\n",
            "1       2.0   NaN  106000\n",
            "2       4.0   NaN  178100\n",
            "3       NaN   NaN  140000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 4,
        "id": "IsKfquUp2MTt"
      },
      "source": [
        "## Handling Missing Data\n",
        "\n",
        "Note that \"NaN\" entries are missing values.\n",
        "To handle missing data, typical methods include *imputation* and *deletion*,\n",
        "where imputation replaces missing values with substituted ones,\n",
        "while deletion ignores missing values. Here we will consider imputation.\n",
        "\n",
        "By integer-location based indexing (`iloc`), we split `data` into `inputs` and `outputs`,\n",
        "where the former takes the first two columns while the latter only keeps the last column.\n",
        "For numerical values in `inputs` that are missing,\n",
        "we [**replace the \"NaN\" entries with the mean value of the same column.**]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 5,
        "tab": [
          "mxnet"
        ],
        "id": "Ns-mBHbV2MTu",
        "outputId": "4c4ae55b-f6b1-48b4-fa50-89432bc95671",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]\n",
        "inputs = inputs.fillna(inputs.mean())\n",
        "print(inputs)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   NumRooms Alley\n",
            "0       3.0  Pave\n",
            "1       2.0   NaN\n",
            "2       4.0   NaN\n",
            "3       3.0   NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 6,
        "id": "9bBz3RTq2MTu"
      },
      "source": [
        "[**For categorical or discrete values in `inputs`, we consider \"NaN\" as a category.**]\n",
        "Since the \"Alley\" column only takes two types of categorical values \"Pave\" and \"NaN\",\n",
        "`pandas` can automatically convert this column to two columns \"Alley_Pave\" and \"Alley_nan\".\n",
        "A row whose alley type is \"Pave\" will set values of \"Alley_Pave\" and \"Alley_nan\" to 1 and 0.\n",
        "A row with a missing alley type will set their values to 0 and 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 7,
        "tab": [
          "mxnet"
        ],
        "id": "xoO_-ekN2MTu",
        "outputId": "d215724d-a8f0-44ea-db02-e53a5992a2b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "inputs = pd.get_dummies(inputs)\n",
        "print(inputs)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   NumRooms  Alley_Pave\n",
            "0       3.0           1\n",
            "1       2.0           0\n",
            "2       4.0           0\n",
            "3       3.0           0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 8,
        "id": "FhDQyYBE2MTv"
      },
      "source": [
        "## Conversion to the Tensor Format\n",
        "\n",
        "Now that [**all the entries in `inputs` and `outputs` are numerical, they can be converted to the tensor format.**]\n",
        "Once data are in this format, they can be further manipulated with those tensor functionalities that we have introduced in :numref:`sec_ndarray`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 9,
        "tab": [
          "mxnet"
        ],
        "id": "QTw953n92MTv",
        "outputId": "424d9702-360c-4a5e-e516-745e66ba7f7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from mxnet import np,npx\n",
        "\n",
        "X, y = np.array(inputs.values,ctx=npx.gpu()), np.array(outputs.values, ctx=npx.gpu())\n",
        "X, y"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[3., 1.],\n",
              "        [2., 0.],\n",
              "        [4., 0.],\n",
              "        [3., 0.]], dtype=float64, ctx=gpu(0)),\n",
              " array([127500, 106000, 178100, 140000], dtype=int64, ctx=gpu(0)))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 12,
        "id": "D2sSHRxo2MTv"
      },
      "source": [
        "## Summary\n",
        "\n",
        "* Like many other extension packages in the vast ecosystem of Python, `pandas` can work together with tensors.\n",
        "* Imputation and deletion can be used to handle missing data.\n",
        "\n",
        "\n",
        "## Exercises\n",
        "\n",
        "Create a raw dataset with more rows and columns.\n",
        "\n",
        "1. Delete the column with the most missing values.\n",
        "2. Convert the preprocessed dataset to the tensor format.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 13,
        "tab": [
          "mxnet"
        ],
        "id": "tf566Yhy2MTw"
      },
      "source": [
        "[Discussions](https://discuss.d2l.ai/t/28)\n"
      ]
    }
  ]
}